{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBQoduo8jJxChRDqf4WHtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jawad-repo/LLM_Urdu_Text_Prediction_asafaya_bert-base-arabic/blob/main/LLM_Urdu_Text_Prediction_asafaya_bert_base_arabic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc4MNV4Iw5PR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "# Example Urdu sentences (replace with your actual data)\n",
        "sentences = [\n",
        "    \"آپ کی خوشی کا سبب کیا ہے؟\",\n",
        "    \"یہ خبر درست ہے یا نہیں؟\",\n",
        "    # Add more sentences here\n",
        "]\n",
        "\n",
        "# Example labels (0 for false, 1 for true)\n",
        "labels = [1, 0]  # Adjust labels according to your data\n",
        "\n",
        "# Tokenize input sentences\n",
        "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "# Create a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((dict(inputs), labels))\n",
        "\n",
        "# Fine-tune the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "model.fit(dataset.shuffle(len(sentences)).batch(16), epochs=3)\n",
        "\n",
        "# Now you can use the fine-tuned model for predictions\n",
        "# Example prediction:\n",
        "test_sentence = \"کیا یہ خبر درست ہے؟\"\n",
        "test_input = tokenizer(test_sentence, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "predictions = model.predict(test_input)\n",
        "predicted_class = tf.argmax(predictions.logits, axis=1).numpy()[0]\n",
        "\n",
        "if predicted_class == 1:\n",
        "    print(f\"'{test_sentence}' is true.\")\n",
        "else:\n",
        "    print(f\"'{test_sentence}' is false.\")"
      ]
    }
  ]
}